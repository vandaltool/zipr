        }
        } || [];
        ## ...
       };
# ==========
###########################
##############################
		    } ); 
$0 = $1 if $0 =~ m:/([^/]+)$:;
$0 Ver $VERSION
               Added --record_log_pos.
Add option to FLUSH STATUS just before UNLOCK TABLES.
Add option to lock each table in turn for people who don\'t need
	# add option to preserve mod time etc of copied files
	# add recursive option for scp
Add support for forthcoming MySQL ``RAID'' table subdirectory layouts.
Add support for other copy methods (e.g., tar to single file?).
    "addtodest!",
  --addtodest          don\'t rename target dir if it exists, just add files to it
# a list of hash-refs containing:
All but the first should use the --addtodest option so the tables
all end up in the same directory.
    "allowold!",
    allowold	=> 0,	# for safety
  --allowold           don\'t abort if target dir already exists (rename it _old)
        # Also, flush tables to make on-disk copy up to date
and 'man ssh' are your friends.
a new name. The new name is the original name with the suffix
any corruptions that could occur if the table files were simply copied
Any existing versions of the backup directory are deleted.
appended. 
        { !/^(apply_status|schema|general_log|slow_log)$/ } @dbh_base_tables
are copied;  You can restore the indexes with isamchk -r or myisamchk -r
  ## "Argument list too long".
    $ARGV[0] =~ s{^([^\.]+)\./(.+)/$}{$1};
A sample log-pos table definition:
As each database is copied, an entry is written to the specified
Ask Bjoern Hansen - Cleanup code to fix a few bugs and enable -w again.
# as short as possible, and only start when we know that we should
        ## assume it's there?
# at all, the defaults will be used (login name, no password).
    AutoCommit => 1,
backed up separately (and thus possibly not be logically consistent
# --- bail out if all specified databases are empty ---
# be able to complete without error.
Behaves as for the --allowold, with the additional feature 
Be silent except for errors.
    binmode(INPUT, ":raw");
# but WITHOUT ANY WARRANTY; without even the implied warranty of
  --checkpoint=#       insert checkpoint entry into specified db.table
    "checkpoint=s",
checkpoint-table.  This has the happy side-effect of updating the
# --- check that checkpoint table exists if specified ---
# --- check that log_pos table exists if specified ---
        chown $f_info[4], $f_info[5], $tgt_dirpath;
  --chroot=#           base directory of chroot jail in which mysqld operates
    "chroot=s",
          @chunk=();
          $chunk_length= 0;
      $chunk_length+= length($_);
    closedir( DBDIR );
      close $fh || die "Error on close of $tmp: $!\n";
    close INPUT;
      close OUTPUT	   || die "Error on close of $to: $!\n";
            `@cmd` || die "Error: @cmd failed ($?) while copying files.\n";
# --- connect to the database ---
  # convert existing READ lock on checkpoint and/or log_pos table into WRITE lock
copied files into it.
Copy all databases with names matching the pattern.
Copy all tables with names matching pattern2 from all databases with
    copy_index($opt{method}, \@files,
Copy only tables matching pattern. Shell metacharacters ( (, ), |, !,
Copy only tables not matching pattern. For example, to copy tables
# Copy only the header of the index file
# Copyright (c) 2000, 2010, Oracle and/or its affiliates. All rights reserved.
	$cp.= " -p" if $^O =~ m/^(solaris|linux|freebsd|darwin)$/;
	$cp.= " -r" if $^O =~ /m^(solaris|linux|freebsd|darwin)$/ && $method =~ /^scp\b/;
CREATE TABLE log_pos (
# --- create target directories if we are using 'cp' ---
cross-table integrity.
database name(s).
    $datadir= $opt{chroot}.$datadir if ($opt{chroot});
	       "$datadir/$rdb->{src}", $rdb->{target} );
$datadir =~ s:/$::;
         db_1./^nice_table/ user@some.system.dom:~/path/to/new_directory
# @db_desc
    @db_desc = map { s{^([^\.]+)\./(.+)/$}{$1}; { 'src' => $_, 't_regex' => ( $2 ? $2 : '.*' ) } } @ARGV;
    @db_desc = ( { 'src' => $ARGV[0], 't_regex' => ( $2 ? $2 : '.*' ) } );
	@db_files = grep { not /\.(ISM|MYI)$/ } @db_files;
        @db_files = keys %db_files;
        $db_files{$name} = $1 if ( $name =~ /(.+)\.\w+$/ );
        @db_files = ($negated
    @db_files = sort @db_files;
      @dbh_base_tables = grep 
        @dbh_base_tables = ( $negated 
    $dbh->disconnect();
$dbh->disconnect;
    $dbh->do( "FLUSH LOGS" ) if ( $opt{flushlog} );
        $dbh->do("FLUSH TABLES /*!32323 $hc_tables */");
	$dbh->do("FLUSH TABLES /*!32323 $hc_tables */");
        $dbh->do("FLUSH TABLES $hc_base_tables WITH READ LOCK")
        $dbh->do("LOCK TABLES $hc_locks");
        $dbh->do("LOCK TABLES $hc_views READ") if ( $hc_views );
      $dbh->do( qq{ insert into $opt{checkpoint} (src, dest, msg) 
	$dbh->do( qq{ replace into $table_name 
    $dbh->do( "RESET MASTER" ) if ( $opt{resetmaster} );
    $dbh->do( "RESET SLAVE" ) if ( $opt{resetslave} );
    $dbh->do("UNLOCK TABLES");
                                     $dbh->quote_identifier($db) .
            $dbh->selectall_arrayref('SHOW FULL TABLES FROM ' .
        @dbh_views = ( $negated 
    "debug",
  --debug              enable debug
Debug messages are displayed.
    # delete any @targets 
    # delete _old unless $opt{keepold}
  dest varchar(60)
	die "Can\'t create/open file in $opt_tmpdir\n";
    die "Can't hotcopy to '", join( "','", @existing ), "' because directory\nalready exist and the --allowold or --addtodest options were not given.\n"
    die "Can't read index header from $from\n" if ($length < 1024);
	die "Can't use unsupported method '$method'\n";
      die "Can't use unsupported method '$opt{method}'\n";
    die "copying multiple databases, but last argument ($tgt_dirname) is not a directory\n"
    || die "datadir not in mysqld variables";
    die "Error accessing Checkpoint table ($opt{checkpoint}): $@"
    die "Error accessing log_pos table ($opt{record_log_pos}): $@"
  die "Error: expected \$opt{suffix} to exist" unless ( exists $opt{suffix} );
	die "Error when writing data to $tmp: $!\n";
	die "Error when writing data to $to: $!\n";
  die "Invalid db.table name '$name'" if (@cruft || !defined $db || !defined $table );
    die join( "\n", @failed );
      die "Last argument ($tgt_dirname) is not a directory\n"
	die "master status is undefined" if !defined $file || !defined $position;
die "No tables to hot-copy" unless ( length $hc_locks );
    die @_, $OPTIONS;
  die "Target '$tgt_name' doesn't look like a database name or directory path.\n";
different from 'localhost' will trigger mysqlhotcopy to use TCP/IP connection.
directory is deleted - unless the --keepold flag is set.  If the copy fails,
Display commands without actually doing them.
Display help-screen and exit.
# Documentation continued at end of file
                       doesn't have FLUSH TABLES WITH READ LOCK fully implemented.
# Do not initialize user or password options; that way, any user/password
Don\'t include index files in copy. Only up to the first 2048 bytes
Don't rename target directory if it already exists, just add the
    "dryrun|n",
$dsn  = ";host=" . (defined($opt{host}) ? $opt{host} : "localhost");
$dsn .= ";mysql_socket=$opt{socket}" if $opt{socket};
$dsn .= ";port=$opt{port}" if $opt{port};
Each database is copied back into the originating datadir under
  # Earlier versions of DBD return table name non-quoted,
    else
    else {
	} else {
elsif (defined($tgt_name) && ($tgt_name =~ m:/: || $tgt_name eq '.')) {
    elsif ($opt{method} eq 'cp')
    elsif ($opt{method} =~ /^scp\b/)
    elsif ($opt{method} =~ /^scp\b/) 
    elsif ($opt{method} =~ /^scp\b/) {
elsif ( $opt{suffix} ) {
Emil S. Hansen - Added resetslave and resetmaster.
encouraged *not* to use this option as every user would be able to see the
etc.) have to be escaped (e.g., \). For example, to select all tables
        eval {
    eval {
  eval { copy_files($opt{method}, \@files, $rdb->{target}); };
    eval { $dbh->do( qq{ select host, time_stamp, log_file, log_pos, master_host, master_log_file, master_log_pos
    eval { $dbh->do( qq{ select time_stamp, src, dest, msg 
    exit(0);
    # explicit destination directory specified
Extend the individual table copy to allow multiple subsets of tables
#   'files'   - array-ref to list of files to be copied
  @files = @{$rdb->{index}};
    ## filter out certain system non-lockable tables. 
    ## filter (out) files specified in t_regex
        ## filter (out) tables specified in t_regex
        ## filter (out) views specified in t_regex
               Fixed cleanup of targets when hotcopy fails. 
        Fixes for --method=scp.
    "flushlog",
    flushlog    => 0,
  --flushlog           flush logs once all tables are locked 
        # flush tables to make on-disk copy up to date
    foreach my $dir ( @dir ) {
        foreach my $dir ( @existing ) {
  foreach my $file (@$files)
      foreach my $rdb ( @db_desc ) {
    foreach my $rdb ( @db_desc ) {
  foreach my $rdb ( @db_desc ) {
	foreach my $rdb ( @db_desc ) {
foreach my $rdb ( @db_desc )
foreach my $rdb ( @db_desc ) {
  foreach my $table ( grep { defined } ( $opt{checkpoint}, $opt{record_log_pos} ) ) {
  foreach (@sources) {
        ## for some reason system fails but backticks works ok for scp...
			 from $opt{checkpoint} where 1 != 1} );
			 from $opt{record_log_pos} where 1 != 1} );
    ## generate regex for tables/files
    ## get list of files to copy
# --- get list of tables and views to hotcopy ---
GetOptions( \%opt,
Getopt::Long::Configure(qw(no_ignore_case)); # disambiguate -p and -P
# --- get target path ---
# --- get variables from database ---
  # given a db.table name, add quotes
    # GNU `cp -r` error message
                     : grep { $db_files{$_} =~ $t_regex } keys %db_files );
                     ? grep { $db_files{$_} !~ $t_regex } keys %db_files
                             : grep { $_ =~ $t_regex } @dbh_base_tables );
                             ? grep { $_ !~ $t_regex } @dbh_base_tables
                       : grep { $_ =~ $t_regex } @dbh_views );
                       ? grep { $_ !~ $t_regex } @dbh_views
    $hc_base_tables .= ", "  if ( length $hc_base_tables && @hc_base_tables );
    $hc_base_tables .= join ", ", @hc_base_tables;
	    $hc_dur, ($hc_dur==1)?"":"s", time - $start_time
    $hc_locks .= ", "  if ( length $hc_locks && @hc_tables );
    $hc_locks .= join ", ", map { "$_ READ" } @hc_tables;
    $hc_locks .= ", $table WRITE" 
        $hc_started = time;	# count from time lock is granted
    @hc_tables = (@hc_base_tables, @hc_views);
    $hc_views .= ", "  if ( length $hc_views && @hc_views );
    $hc_views .= join " READ, ", @hc_views;
=head1 AUTHOR
=head1 DESCRIPTION
=head1 NAME
=head1 OPTIONS
=head1 SYNOPSIS
=head1 TO DO
=head1 WARRANTY
    "help",
  -?, --help           display this help-screen and exit
Here "live" means that the database server is running and the database
  -h, --host=#         hostname for local server when connecting over TCP/IP
    "host|h=s",
		  $hostname, $file, $position, 
Hostname for local server when connecting over TCP/IP.  By specifying this
  host            varchar(60) NOT null,
# --- HOT-COPY COMPLETE ---
    # hotcopy failed - cleanup
    # hotcopy worked
      if ( $@ );
    if ( $@ ) {
    if ( $@ );
    if ( @ARGV == 2 ) {
  if ($chunk_length > 0) { # do not forget last small chunk
      if ($chunk_length > $chunk_limit) {
        if ($cp_status != 0) {
      if ( @db_desc > 1 && !(-e $tgt_dirname && -d $tgt_dirname ) );
	if ( $dbh->{mysql_serverinfo} =~ /^3\.23/ ) {
    if ($db =~ m/^mysql$/i)
if ( defined $opt{regexp} ) {
if (defined($tgt_name) && length $tgt_name ) {
if (defined($tgt_name) && $tgt_name =~ m:^\w+$: && @db_desc <= 1)
	if ( -d $tgt_oldpath ) {
	if (!(-e $tgt_dirname && -d $tgt_dirname ) );
    if (@existing) {
  if ( @existing && !($opt{allowold} || $opt{addtodest}) )
    if ( @existing && !$opt{keepold} ) {
if ( @failed ) {
          if ( $hc_base_tables );
    if ($method =~ /^s?cp\b/)  # cp or scp with optional flags
If only a single db_name is supplied and the --suffix flag is not
  if ( $opt{checkpoint} ) {
if ( $opt{checkpoint} ) {
if ( $opt{checkpoint} || $opt{record_log_pos} ) {
    if ( $opt{dryrun} )
    if ( $opt{dryrun} ) {
	if ( $opt{dryrun} ) {
if ( $opt{dryrun} ) {
if ($opt{method} =~ /^cp\b/)
    if ($opt{noindices}) {
    if ( $opt{old_server} ) {
    if ( $opt{record_log_pos} ) {
if ( $opt{record_log_pos} ) {
if ( $opt{regexp} || $opt{suffix} || @ARGV > 2 ) {
    if ( $opt{regexp} =~ s{^/(.+)/\./(.+)/$}{$1} ) {
  if ($rdb->{index})
    if ($rdb->{t_regex}) {
      if (syswrite($fh,$buff) != length($buff))
      if (syswrite(OUTPUT,$buff) != length($buff))
    if ($to_other_database)
in database db1 whose names begin with 'foo' or 'bar':
#   'index'   - array-ref to list of indexes to be copied
        @index_files= grep { /\.(ISM|MYI)$/ } @db_files;
                       in my.cnf, which is recommended)
# in order to get a consistent snapshot of the database
In this situation, I<if> you are happy for groups of tables to be
=item --addtodest
=item --allowold
=item --checkpoint checkpoint-table
=item db_name./~pattern/
=item db_name./pattern/
=item  --debug
=item --flushlog
=item -?, --help
=item -h, -h, --host=#
=item --keepold
=item  --method=#           
=item -n, --dryrun
=item  --noindices          
=item --old_server
=item -p, --password=#     
=item -P, --port=#         
=item -q, --quiet              
=item --record_log_pos log-pos-table
=item --regexp pattern
=item --regexp /pattern1/./pattern2/
=item --resetmaster
=item --resetslave
=item -S, --socket=#         
=item --suffix suffix
=item -u, --user=#         
Jeremy D. Zawodny - Removed deprecated DBI calls.  Fixed bug which
Just before the database files are copied, update the record in the
    ## keep in sync with mysqldump.
    "keepold!",
    keepold	=> 0,
  --keepold            don\'t delete previous (now renamed) target when done
Liberal use of the --debug option will help you figure out what\'s
# Library General Public License for more details.
# License along with this library; if not, write to the Free
# License as published by the Free Software Foundation; version 2
        # Lock base tables and views separately.
        # Lock base tables and views separately, as 'FLUSH TABLES <tbl_name>
locked, and before they are copied.
locked, and before they are copied. Useful if you are recovering a
log_file and log_pos columns, and establish the position in the binary
  log_file        varchar(32) default NULL,
  log_pos         int(11)     default NULL,
log-pos-table from the values returned from "show master status" and
logs that any slaves of this host should adopt if initialised from
# MA 02110-1301, USA
Martin Waite - Added checkpoint, flushlog, regexp and dryrun options.
Martin Waite - Fix to handle database name that contains space.
	    ($master_host, $log_file, $log_pos ) 
		  $master_host, $log_file, $log_pos  );
                          master_host=?, master_log_file=?, master_log_pos=? }, 
  master_host     varchar(60) NULL,
master_log_file, and master_log_pos, corresponding to the coordinates
  master_log_file varchar(32) NULL,
  master_log_pos  int NULL,
may be in active use. And "stable" means that the copy will not have
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    method	=> "cp",
Method for copy (only "cp" currently supported). Alpha support for
  --method=#           method for copy (only "cp" currently supported)
    "method=s",
        mkdir($tgt_dirpath, 0750) or die "Can't create '$tgt_dirpath': $!\n"
# modify it under the terms of the GNU Library General Public
Monty - Working --noindex (copy only first 2048 bytes of index file).
Move any existing version of the destination to a backup directory for
  msg varchar(255)
    "mv!",
    my $buff;
  my @chunk= (); 
  my $chunk_length= 0;
  my $chunk_limit= 100 * 1024; # 100 kB
    my @cmd= @_;
    my @cmd;
	my $cp = $method;
        my $cp_status = system "@cmd > /dev/null";
my $datadir = $mysqld_vars{'datadir'}
    my ( $db ) = @_;
my @db_desc = ();
    my $db_dir = "$datadir/$db";
    my @db_files;
    my %db_files;
    my @dbh_base_tables = get_list_of_tables( $db );
my $dbh = DBI->connect("dbi:mysql:$dsn;mysql_read_default_group=mysqlhotcopy",
  my ( $dbh, $sql ) = @_;
    my ( $dbh, $table_name ) = @_;
    my @dbh_tables = (@dbh_base_tables, @dbh_views);
    my @dbh_views = get_list_of_views( $db );
    my $db = $rdb->{src};
  my ($db, $table, @cruft) = split( /\./, $name );
    my ( @dir ) = @_;
my $dsn;
my @existing = ();
my @failed = ();
      my ($fh, $tmp)= tempfile('mysqlhotcopy-XXXXXX', DIR => $opt_tmpdir) or
	my ($file,$position) = get_row( $dbh, "show master status" );
  my @files = map { "$datadir/$rdb->{src}/$_" } @{$rdb->{files}};
        my @f_info= stat "$datadir/$rdb->{src}";
    my $from="$source/$file";
my $hc_base_tables = "";
    my @hc_base_tables = map { quote_names("$db.$_") } @dbh_base_tables;
my $hc_dur = time - $hc_started;
my $hc_locks = "";
my $hc_started = time;	# count from time lock is granted
my $hc_tables = "";
    my @hc_tables = (@hc_base_tables, @hc_views);
my $hc_views = "";
    my @hc_views = map { quote_names("$db.$_") } @dbh_views;
	my $hostname = hostname();
    my @index_files=();
    my $length=read INPUT, $buff, 2048;
	my ($master_host, $log_file, $log_pos ); 
  my ($method, $files, $source, $target) = @_;
    my ($method, $files, $target) = @_;
  my $method= shift @sources;
    my $msg = ( $@ ) ? "Failed: $@" : "Succeeded";
my %mysqld_vars;
  my ( $name ) = @_;
    my $negated;
my $num_base_tables = 0;
my $num_files = 0;
my $num_tables = 0;
my $num_views = 0;
	my @oldies = map { $_ . '_old' } @existing;
my %opt = (
my $OPTIONS = <<"_OPTIONS";
my $opt_tmpdir = $ENV{TMPDIR} || "/tmp";
	my $row_hash = get_row_hash( $dbh, "show slave status" );
  my @sources= @_;
    $mysqld_vars{ $var } = $value;
  mysqlhotcopy db_name
  mysqlhotcopy db_name_1 ... db_name_n /path/to/new_directory
  mysqlhotcopy db_name_1./regex_1/ db_name_1./regex_2/ ... db_name_n./regex_n/ /path/to/new_directory
  mysqlhotcopy db_name./^\(foo\|bar\)/
  mysqlhotcopy db_name./~regex/
  mysqlhotcopy db_name./regex/
  mysqlhotcopy db newdb  t1 t2 /^foo_/ : t3 /^bar_/ : +
mysqlhotcopy - fast on-line hot-backup utility for local MySQL databases and tables
# [mysqlhotcopy] groups will be read from standard options files.
    mysqlhotcopy --indices --method=cp db1./^\(foo\|bar\)/
    mysqlhotcopy --indices --method=cp db1./~^\(foo\|bar\)/
   mysqlhotcopy --indices --method=cp --regexp /foo$/./^bar/
mysqlhotcopy is designed to make stable copies of live MySQL databases.
  mysqlhotcopy --method='scp -Bq -i /usr/home/foo/.ssh/identity' --user=root --password=secretpassword \
  mysqlhotcopy --suffix=_copy db_name_1 ... db_name_n
MySQL update-log (if it is switched on) giving a good indication of
    my $start = time;
my $start_time = time;
  my $sth = $dbh->prepare($sql);
    my $sth_dbs = $dbh->prepare("show databases");
my $sth_vars = $dbh->prepare("show variables like 'datadir'");
    my $tables =
  my $target= pop @sources;
    my @targets = ();
my ($tgt_dirname, $to_other_database);
    my $tgt_dirpath = "$rdb->{target}";
my $tgt_name = undef;
	my $tgt_oldpath = $dir . '_old';
    my $to="$target/$file";
    my $t_regex = '.*';
    my $t_regex;
my $VERSION = "1.23";
    my $views =
names begin with 'bar' from all databases which names end with 'foo':
names matching pattern1. For example, to select all tables which
  -n, --dryrun         report actions without doing them
        $negated = $t_regex =~ s/^~//;     ## note and remove negation operator
'newdb' is either the name of the new database, or the full path name
	    next;
	next if $db_name =~ m/^information_schema$/i;
  next unless @files;
    "noindices!",
    noindices	=> 0,
  --noindices          don\'t include full index files in copy
not copied by the previous subsets.
	# not critical, but nice to have
Note that using scp will lock your tables for a _long_ time unless
# Note that we try to keep the time between the LOCK and the UNLOCK
    ## Now concatenate the base table and view arrays.
    $num_base_tables += scalar @hc_base_tables;
    $num_files  += scalar @{$rdb->{files}};
    $num_tables += $num_base_tables + $num_views;
	    $num_tables, $num_files,
    $num_views += scalar @hc_views;
of keeping the backup directory after the copy successfully completes.
# of the License.
of the new database file. The database should not already exist.
of the next to the last event the slave has executed. The slave or its
    "old_server",
      --old_server     connect to old MySQL-server (before v5.5) which
one of the config files, normally /etc/my.cnf or your personal ~/.my.cnf.
on the backup.
    opendir(DBDIR, $db_dir ) 
    open(INPUT, "<$from") || die "Can't open file $from: $!\n";
      open(OUTPUT,">$to")   || die "Can\'t create file $to: $!\n";
$opt{allowold} = 1 if $opt{keepold};
    $opt{checkpoint} = quote_names( $opt{checkpoint} );
_OPTIONS
# options specified in option files will be used.  If no values are specified
$opt{quiet} = 0 if $opt{debug};
    $opt{record_log_pos} = quote_names( $opt{record_log_pos} );
	$opt{suffix} = "_copy";
$opt_tmpdir= $opt{tmpdir} if $opt{tmpdir};
                        $opt{user}, $opt{password},
      or die "Cannot open dir '$db_dir': $!";
	  or die "Can't rename $dir=>$tgt_oldpath: $!\n";
) or usage("Invalid option");
	      or warn "Can't rename ${dir}_old to $dir: $!\n";
password in the process list. Instead use the '[mysqlhotcopy]' section in
    "password|p=s",
Password to use when connecting to the server. Note that you are strongly
Patches adding bug fixes, documentation and new features are welcome.
Paul DuBois - Remove end '/' from directory names.
	# perform the actual copy
# --- PERFORM THE HOT-COPY ---
Please send these to internals@lists.mysql.com.
    "port|P=s",
Port to use when connecting to MySQL server with TCP/IP.  This is only used
  -p, --password=#     password to use when connecting to server (if not set
  -P, --port=#         port to use when connecting to local server with TCP/IP
  PRIMARY KEY  (host) 
        print "@cmd\n";
    print "Copying ".@$files." files...\n" unless $opt{quiet};
  print "Copying indices for ".@$files." files...\n" unless $opt{quiet};  
	print "Deleting previous copy in @oldies\n" if $opt{debug};
	    print "Deleting previous 'old' hotcopy directory ('$tgt_oldpath')\n" unless $opt{quiet};
    print "Deleting @targets \n" if $opt{debug};
print Dumper( \@db_desc ) if ( $opt{debug} );
    PrintError => 0,
        print "Executing '@cmd'\n" if $opt{debug};
	print "Existing hotcopy directory renamed to '$tgt_oldpath'\n" unless $opt{quiet};
    printf "$0 copied %d tables (%d files) in %d second%s (%d seconds overall).\n",
        printf "Flushed $num_base_tables tables with read lock ($hc_base_tables) in %d seconds.\n",
        printf "Flushed tables ($hc_tables) in %d seconds.\n", time-$start unless $opt{quiet};
        print "Filtering tables with '$t_regex'\n" if $opt{debug};
        printf "Locked $num_tables tables in %d seconds.\n", time-$start unless $opt{quiet};
        printf "Locked $num_views views ($hc_views) in %d seconds.\n",
    print "FLUSH LOGS\n" if ( $opt{flushlog} );
        print "FLUSH TABLES /*!32323 $hc_tables */\n";
        print "FLUSH TABLES $hc_base_tables WITH READ LOCK\n"
printf "Unlocked tables.\n" unless $opt{quiet};
        print "LOCK TABLES $hc_locks\n";
        print "LOCK TABLES $hc_views READ\n" if ( $hc_views );
        print "mkdir $tgt_dirpath, 0750\n";
      print "$opt{method}-header $from $to\n";
	    print "rename $dir, $tgt_oldpath\n";
    print "RESET MASTER\n" if ( $opt{resetmaster} );
    print "RESET SLAVE\n" if ( $opt{resetslave} );
	print "Restoring @existing from back-up\n" if $opt{debug};
	print "rm -rf @oldies\n" 
	    print "rmtree $tgt_oldpath\n" if ( -d $tgt_oldpath );
    print "UNLOCK TABLES\n";
    print "Using copy suffix '$opt{suffix}'\n" unless $opt{quiet};
      push @chunk, $_;
	push @db_desc, { 'src' => $db_name, 't_regex' => $t_regex } if ( $db_name =~ m/$opt{regexp}/o );
    push @existing, $rdb->{target} if ( -d  $rdb->{target} );
  push @failed, "$rdb->{src} -> $rdb->{target} failed: $@"
        push @targets, $rdb->{target} if ( -d  $rdb->{target} );
  -q, --quiet          be silent except for errors
    "quiet|q",
               RAID tables are now copied (don't know if this works over scp).
    RaiseError => 1,
Ralph Corderoy - Added synonyms for commands.
    $rdb->{files}  = [ @db_files ];
    $rdb->{index}  = [ @index_files ];
    $rdb->{tables} = [ @hc_tables ];
    $rdb->{target} = "$datadir/$rdb->{src}$opt{suffix}";
	$rdb->{target} = "$tgt_dirname";
	    $rdb->{target} = "$tgt_dirname/$rdb->{src}";
	$rdb->{target} = "$tgt_dirname/$rdb->{src}";
# read lock all the tables we'll be copying
really going on when you do an scp.
	record_log_pos( $dbh, $opt{record_log_pos} );
  --record_log_pos=#   record slave and master status in specified db.table
    "record_log_pos=s",
  --regexp=#           copy all databases with names matching regexp
    "regexp=s",
    ## remove indices unless we're told to keep them
    # Remove trailing slashes (needed for Mac OS X)
	    rename("${dir}_old", $dir )
	rename($dir, $tgt_oldpath)
    # rename _old copy back to original
    "resetmaster",
  --resetmaster        reset the binlog once all tables are locked
    "resetslave",
  --resetslave         reset the master.info once all tables are locked
Reset the bin-log by executing "RESET MASTER" after all tables are
Reset the master.info by executing "RESET SLAVE" after all tables are
# --- resolve database names from regexp ---
# --- resolve targets for copies ---
resulted in nothing being copied when a regexp was specified but no
retire_directory( @existing ) if @existing && !$opt{addtodest};
  return "`$db`.`$table`";
    return (map { $_->[0] } @$tables);
    return (map { $_->[0] } @$views);
  # returns it quoted. Let's have a support for both.
  return $sth->fetchrow_array();
  return $sth->fetchrow_hashref();
	rmtree([@oldies]);
    rmtree([@targets]);
	    rmtree([$tgt_oldpath],0,1);
Rotate the log files by executing "FLUSH LOGS" after all tables are
	      = @{$row_hash}{ qw / Master_Host Log_File Pos / };
	      = @{$row_hash}{ qw / Master_Host Relay_Master_Log_File Exec_Master_Log_Pos / };
          safe_simple_system($method, @chunk, $target);
      safe_simple_system($method, @chunk, $target); 
	safe_system( $cp, (map { "'$_'" } @$files), "'$target'" );
      safe_system("$opt{method} $tmp $to");
Scott Wiersdorf - Added table regex and scp support.
scp method. --keepold and --allowold are meaningless with scp.
scp or rsync the files at your leisure.
"scp" was added in November 2000. Your experience with the scp method
  ## see http://www.linuxjournal.com/article.php?sid=6060).
(See the chapter 'my.cnf Option Files' in the manual.)
server in a mutual replication setup.
			  set host=?, log_file=?, log_pos=?, 
should never trust backup software without studying the code yourself.
"show slave status". The master status values are stored in the
siblings can connect to the master next time and request replication
slave in a replication setup.
    "socket|S=s",
# Software Foundation, Inc., 51 Franklin St, Fifth Floor, Boston,
  ## @sources = list of source file names
#   'src'     - name of the db to copy
  src varchar(32)
  -S, --socket=#       socket to use when connecting to local server
starting from the recorded values. 
        $start = time;
    $sth_dbs->execute;
  $sth->execute;
$sth_vars->execute;
Study the code inside this script and only rely on it if I<you> believe
sub copy_files {
sub copy_index
sub get_list_of_tables {
sub get_list_of_views {
sub get_row {
sub get_row_hash {
sub quote_names {
sub record_log_pos {
sub retire_directory {
sub safe_simple_system {
sub safe_system {
    substr($tgt_dirpath, 1) =~ s|/+$||;
sub usage {
  # such as DBD-2.1012 and the newer ones, such as DBD-2.9002
    "suffix=s",
  --suffix=#           suffix for names of copied databases
supplied, then "--suffix=_copy" is assumed.
tables and you don't want to have all the tables locked for the
#   'tables'  - array-ref to list of tables in the db
  $table=~ s/\`//g;
#   'target'  - destination directory of the copy
    $tgt_dirname = "$datadir/$tgt_name";
    $tgt_dirname = $tgt_name;
	$tgt_name   = $ARGV[1];
  $tgt_name="" if (!defined($tgt_name));
    $tgt_name   = pop @ARGV unless ( exists $opt{suffix} );
that do not begin with foo nor bar:
that it does the right thing for you.
the backup directory is restored.
The backup directory name is the original name with "_old" appended.
The checkpoint-table must contain at least the following fields:
The destination directory _must exist_ on the target machine using the
the duration of the copy. If the copy successfully completes, the backup 
The name of the checkpoint table should be supplied in database.table format.
The name of the log-pos table should be supplied in database.table format.
the same database each with different db_name./table_regex/.
this dump.  The slave status values are stored in master_host,
This is most useful when backing up a database with many large
# This program is distributed in the hope that it will be useful,
# This program is free software; you can redistribute it and/or
This software is free and comes without warranty of any kind. You
Tim Bunce
  time_stamp      timestamp(14) NOT NULL,
  time_stamp timestamp not null
               time-$start unless $opt{quiet};
  --tmpdir=#	       temporary directory (instead of $opt_tmpdir)
    "tmpdir|t=s",
to be specified on the command line:
$to_other_database=0;
    $to_other_database=1;
        $t_regex = $2;
        $t_regex = qr/$t_regex/;           ## make regex string from
        $t_regex = $rdb->{t_regex};        ## assign temporary regex
#   't_regex' - regex describing tables in src
  Try \'perldoc $0\' for more complete documentation
            ## try something else
		  undef, 
UNIX domain socket to use when connecting to local server.
            unless -d $tgt_dirpath;
	unless ( $hc_locks =~ s/$table\s+READ/$table WRITE/ );
    unless( keys %db_files ) {
	unless $opt{quiet};
      unlink $tmp;
Usage: $0 db_name[./table_regex/] [new_db_name | directory]
    usage("Database name to hotcopy not specified") unless ( @ARGV );
usage("") if ($opt{help});
use Data::Dumper;
use DBI;
use File::Basename;
use File::Copy;
use File::Path;
use File::Temp qw(tempfile);
use Getopt::Long;
# use mysql_read_default_group=mysqlhotcopy so that [client] and
Use old server (pre v5.5) commands.
User for database login if not current user.
                                           ## user regex
    "user|u=s",
use strict;
use Sys::Hostname;
use the 'cp' method to copy the tables to some temporary area and then
#!/usr/bin/perl
  ## /usr/src/linux/include/linux/binfmts.h
  -u, --user=#         user for database login if not current user
		      VALUES ( '$rdb->{src}', '$rdb->{target}', '$msg' )
	warn "'$db' is an empty database\n";
            warn "Executing command failed ($cp_status). Trying backtick execution...\n";
	warn "Failed to store master position: $@\n";
      warn "Failed to update checkpoint table: $@\n";
WARNING: THIS PROGRAM IS STILL IN BETA. Comments/patches welcome.
    warn "Unable to retrieve list of tables in $db: $@" if $@;
    warn "Unable to retrieve list of views in $db: $@" if $@;
  ## We have to deal with very long command lines, otherwise they may generate 
    {   # we have to trust scp to hit the target
when using the --host option.
where ":" delimits the subsets, the /^foo_/ indicates all tables
where roll-forward should begin for backup+rollforward schemes.
                                     ' WHERE Table_type = \'BASE TABLE\'')
                                     ' WHERE Table_type = \'VIEW\'')
  ## which is the common limit on Linux (can be read from
    while ( defined( my $name = readdir DBDIR ) ) {
    while ( my ($db_name) = $sth_dbs->fetchrow_array ) {
while ( my ($var,$value) = $sth_vars->fetchrow_array ) {
whole duration.
will vary with your ability to understand how scp works. 'man scp'
  ## With 10000 tables the command line can be around 1MB, much more than 128kB
with names beginning with "foo_" and the "+" indicates all tables
with one another) then you can run mysqlhotcopy several times on
without first being locked and flushed from within the server.
        # ... WITH READ LOCK' (introduced in 5.5) would fail for views.
your network connection is _fast_. If this is unacceptable to you,
# You should have received a copy of the GNU Library General Public
